// ============================================================
// LAWYER MATCHING REQUEST METADATA
// ============================================================
// Timestamp: 2025-04-19T19:37:25.910359
// Request ID: 7347f981
// User ID: 29aa0daa
// Client IP: 127.0.0.1
// Client Hostname: DESKTOP-9BPBDO7
// 
REQUEST HEADERS:
//   Host: 127.0.0.1:8000
//   Connection: close
//   Content-Length: 33624
//   Sec-Ch-Ua-Platform: "Windows"
//   Authorization: Bearer eyJhbGciOiJIUzI1NiIsImtpZCI6IlAyRnNtdXhwRmI2YXBMUWgiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL2tlaHJsaGV5bnhwYnRxenhkanV5LnN1cGFiYXNlLmNvL2F1dGgvdjEiLCJzdWIiOiIyOWFhMGRhYS1mZDcxLTRmY2UtOTA0OC0xYWQ0YWFhNTY1NTYiLCJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNzQ1MTA5ODQ3LCJpYXQiOjE3NDUxMDYyNDcsImVtYWlsIjoicnlhbnNhdmFnZWJhcnJldHRvQGdtYWlsLmNvbSIsInBob25lIjoiIiwiYXBwX21ldGFkYXRhIjp7InByb3ZpZGVyIjoiZ29vZ2xlIiwicHJvdmlkZXJzIjpbImdvb2dsZSJdfSwidXNlcl9tZXRhZGF0YSI6eyJhdmF0YXJfdXJsIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EvQUNnOG9jSjZZQ2lxMWp4UDBOUVg1VGZrQmFuTkctaWtRdEdGVjZsYTJMSm03ZHhYNGtjMlNBPXM5Ni1jIiwiZW1haWwiOiJyeWFuc2F2YWdlYmFycmV0dG9AZ21haWwuY29tIiwiZW1haWxfdmVyaWZpZWQiOnRydWUsImZ1bGxfbmFtZSI6IlJ5YW4gQmFycmV0dG8iLCJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYW1lIjoiUnlhbiBCYXJyZXR0byIsInBob25lX3ZlcmlmaWVkIjpmYWxzZSwicGljdHVyZSI6Imh0dHBzOi8vbGgzLmdvb2dsZXVzZXJjb250ZW50LmNvbS9hL0FDZzhvY0o2WUNpcTFqeFAwTlFYNVRma0Jhbk5HLWlrUXRHRlY2bGEyTEptN2R4WDRrYzJTQT1zOTYtYyIsInByb3ZpZGVyX2lkIjoiMTA3MzQ2ODUzNjQ2NTUwMjgxNzI3Iiwic3ViIjoiMTA3MzQ2ODUzNjQ2NTUwMjgxNzI3In0sInJvbGUiOiJhdXRoZW50aWNhdGVkIiwiYWFsIjoiYWFsMSIsImFtciI6W3sibWV0aG9kIjoib2F1dGgiLCJ0aW1lc3RhbXAiOjE3NDQzNDE0NzV9XSwic2Vzc2lvbl9pZCI6ImRkYTk0NzE2LWM0ODEtNDUzNy1hZjIxLTEwNDg0Yzg4YjcxYSIsImlzX2Fub255bW91cyI6ZmFsc2V9.awi54lorwZQO1upFHfOQxb_h0QhLEB2Y4Go8CZeWdE8
//   User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0
//   Sec-Ch-Ua: "Microsoft Edge";v="135", "Not-A.Brand";v="8", "Chromium";v="135"
//   Content-Type: application/json
//   Sec-Ch-Ua-Mobile: ?0
//   Accept: */*
//   Origin: http://localhost:3000
//   Sec-Fetch-Site: same-origin
//   Sec-Fetch-Mode: cors
//   Sec-Fetch-Dest: empty
//   Referer: http://localhost:3000/lawyer-search
//   Accept-Encoding: gzip, deflate, br, zstd
//   Accept-Language: en-US,en;q=0.9
//   X-Real-Ip: ::1
//   X-Vercel-Deployment-Url: localhost:3000
//   X-Vercel-Forwarded-For: ::1
//   X-Vercel-Id: dev1::vss0o-1745109445843-9d5ba6398e79
//   X-Forwarded-For: ::1
//   X-Forwarded-Port: 3000
//   X-Forwarded-Proto: http
//   X-Forwarded-Host: [::1]:54782
// ============================================================


{
  "user_id": "29aa0daa-fd71-4fce-9048-1ad4aaa56556",
  "uploaded_documents": {
    "resume": true,
    "publications": false,
    "awards": false,
    "recommendation": false,
    "press": false,
    "salary": false,
    "judging": false,
    "membership": false,
    "contributions": false
  },
  "document_summaries": {
    "publications": {
      "extracted_text": "04 OCT 2024  |  VOL 7  |  1\nJournal of Emerging Investigators  \u2022  www.emerginginvestigators.org\nArticleLLM that was built on BERT, is currently ranked seventh for \nthe General Language Understanding Evaluation (GLUE) \nbenchmark (3,4). The GLUE benchmark is a large dataset \nthat creates several fundamental tasks of natural language \nprocessing (NLP) including question answering and text \nclassification, amongst others. The base version of the BERT \nmodel comprises 86 million total parameters while the large \nversion has over 300 million parameters. To be able to fine-tune \nsuch a model on a task, a GPU and a considerable amount of \ntime is required. Additionally, achieving optimal performance \nrequires hyper parameter tweaking, such as training for more/\nless epochs (training iterations) and increasing/decreasing \nthe learning rate (how aggressive the training approach is), \nwhich further the total time complexity. Traditional methods \nattempt to use classical machine learning algorithms (as \nopposed to deep learning neural networks) paired with text \nfeature extraction tools, such as term frequency \u2013  inverse \ndocument frequency vectorizers (TF\u2013IDF) to model textual \ndata (5). These methods are computationally simpler than \ncurrent state of the art techniques, but do not achieve the \nsame level of performance. The primary issue with such \nmethods is that they fail to incorporate textual relationships \ninto the features they provide. However, these methods do \nindicate that machine learning methods can be viable so \nlong as meaningful features are provided. Methods that \nutilize information from the writing process, rather than just \ninformation from the produced text itself, do exist and have \nachieved success. Keystroke logging is the act of recording \nkeyboard events while a user is typing. The data collected \nfrom keystroke loggers can be very informative and reveal \ninformation about textual data that the text itself cannot (6). \nFor example, suppose a writer takes a deep pause when \nwriting, perhaps planning out the rest of their essay or for \nsome other deliberation. Looking at just the written text, it \nwould be impossible to assess that such a pause was ever \ntaken. However, with keystroke log data, one can analyze the \ntime between clicked keys and discover such events.\n Due to the differences in the way current LLM methods \nand keystroke log methods approach text-based problems, \na hybrid approach could improve the results of both. LLM \nmethods offer a detailed look into the text itself and the \ndeeply encoded properties within it, while the keystroke log \napproach uncovers details about the writing process, missing \nfrom the final product. A combination of both should therefore \nprovide the best results on downstream tasks. However, if \nresources are limited, an approach solely using keystroke log \ndata could be advisable as one can fully train a model and \nperform inference with just a CPU in a very short amount of \ntime. Therefore, the use of keystroke log data could not only \nserve as a source of improvement on NLP performance but \ncould also serve as a speedy alternative in many situations.Gradient boosting with temporal feature extraction for \nmodeling keystroke log data\nSUMMARY\nAlthough there has been great progress in the field of \nNatural language processing (NLP) over the last few \nyears, particularly with the development of attention-\nbased models, less research has contributed \ntowards modeling keystroke log data. State of the art \nmethods handle textual data directly and while this \nhas produced excellent results, the time complexity \nand resource usage are quite high for such methods. \nAdditionally, these methods fail to incorporate the \nactual writing process when assessing text and instead \nsolely focus on the content. Therefore, we proposed a \nframework for modeling textual data using keystroke-\nbased features. Such methods pay attention to how \na document or response was written, rather than the \nfinal text that was produced. These features are vastly \ndifferent from the kind of features extracted from raw \ntext but reveal information that is otherwise hidden. \nWe hypothesized that pairing efficient machine \nlearning techniques with keystroke log information \nshould produce results comparable to transformer \ntechniques, models which pay more or less attention \nto the different components of a text sequence in \na far quicker time. Transformer-based methods \ndominate the field of NLP currently due to the strong \nunderstanding they display of natural language. We \nshowed that models trained on keystroke log data are \ncapable of effectively evaluating the quality of writing \nand do it in a significantly shorter amount of time \ncompared to traditional methods. This is significant \nas it provides a necessary fast and cheap alternative \nto increasingly larger and slower LLMs.\nINTRODUCTION\n Transformer attention-based methods have largely \ndominated text-based supervised learning over the last \nfew years, mainly due to publicly available large language \nmodels (LLMs) (1, 2). These models allow for highly efficient \nand effective fine tuning on downstream tasks, such as \nsequence classification and question answering. Despite the \nreduced time it takes to fine tune LLMs relative to training \na model entirely from scratch, the training process can still \ntake considerable time and requires support from a graphics \nprocess unit (GPU).\n Bidirectional encoder representations from transformers \n(BERT) were one of the first LLMs and also one of the first \nmodels to utilize attention, which gave it the unique ability of \nunderstanding how words relate to one another. Decoding-\nenhanced BERT with disentangled attention (DeBERTa), an Ryan Barretto1, Sanjay Barretto1\n1 William Fremd High School, Inverness, Illinois\n04 OCT 2024  |  VOL 7  |  2\nJournal of Emerging Investigators  \u2022  www.emerginginvestigators.org\nhttps://doi.org/10.59720/24-087  Prior research has been conducted on utilizing keystroke \nlog data for modeling certain downstream tasks. Positive \nrelationships have been found between keystroke information \nand students\u2019 writing processes by modeling keystroke \nlog data with heavy tailed probability distributions (7). \nSpecifically, work has demonstrated that task engagement \nand writing efforts may play a big role in the overall quality of \nwriting produced (8). Other research focused on assessing \nstudent writing quality by modeling features extracted from \nkeystroke log data (9). This work demonstrated promising \nresults for uncovering relationships between keystroke log \ndata and writing quality. Each of these works suggest that \nkeystroke information may have strong predictive power for \nthe quality of writing, However, due to the older models that \nwere used in these papers, we believe that the results could \nbe improved upon with newer, advanced machine learning \nmodels. Research has also shown that just the number of \nwords written in an essay within the first 999 keystrokes could \nbe powerful predictors for machine learning models (10). On a \nsimilar note, work has shown writing quality could be modeled \nsuccessfully with just two to five features (variables that can \nbe manipulated to make predictions), with the number of \nkeystrokes for a given essay being the most important (11). \nResearch in 2022 looked at identifying students in need \nof assistance using a variety of features similar to those \nextracted from the 2022 study, using models such as Naive \nBayes, SVM\u2019s, and random forests (12). While this research \nwas insightful, the methods did not address assessing the \nquality of writing.\n Recently, research has been conducted examining the use \nof keystroke dynamics paired with machine learning models \n(13). In this research, the authors use classical machine \nlearning models like SVM\u2019s, random forests, and K-nearest \nneighbors, in addition to deep learning methods like neural \nnetworks. These models were used to analyze keystroke log \ndata to distinguish between the different users who typed \nresponses. The authors ultimately offered a comparative \nanalysis of different models for biometric identification \n(determining the identity of a person), while we have focused \non a single gradient booster\u2019s performance on keystroke log \ndata for analyzing the quality of students\u2019 writing versus the \nperformance of LLMs on the same task. \n We hypothesized that pairing efficient machine learning \ntechniques with keystroke log information will produce \nresults comparable to transformer techniques in less \ntime. We demonstrated that gradient boosters, machine \nlearning algorithms that merge the ideas of neural networks \nand random forests into one algorithm, using keystroke \ninformation are able to produce strong results on assessing \nstudent writing in under a second. It is clear that keystroke log \ndata, normally consisting of keypress speed and frequency, \nwhich describes the writing process, can be just as useful \nfor understanding student writing as the actual writing itself. \nOur results suggest the writing process reveals important \ninformation that is often missed in traditional NLP techniques, \nspecifically within the task of evaluating the quality of writing. \nThis additional information could be helpful not only by itself \nfor efficient and fast data modeling as shown in this paper, but \nalso paired with the original text may provide the entire picture \nof a student\u2019s writing which could lead to improvements on \nmodeling in the field as a whole.RESULTS\n Raw keystroke data consists of the type of key event \ntaking place over time and is then grouped according to the \nsession it took place. Features that were extracted from this \nraw data involve the number of keystroke events, average \ntime taken per keystroke and more ( Table 1 ). A gradient \nboosting classifier was then trained on this extracted data \nto distinguish between different qualities of writing. This \nparticular classifier was chosen because it has been shown to \nbe extremely efficient and accurate when dealing with tabular \ndata. The main metrics for evaluating the model are the root \nmean square error (RMSE) and quadratic weighted kappa \n(QWK). \n The major results looked at are the times it took for a \ncertain model to train and the scores it achieved in predicting \nthe quality of an essay given the actual quality it received by \nhuman raters. On average, each model scored an RMSE \nof 0.6624 taking a total of 0.3774 seconds to train (Figure \n1). The normalized RMSE for each model, on average, was \n0.1104, due to the range of our target variable being equal \nTable 1: Base-level extracted features synthesized from general \npatterns discovered within the raw keystroke log data. These \nfeatures represent simple patterns that were recovered from an \nindividual's writing process. Most features relate to the time it took \nfor keystroke events as well as the types of keystrokes occurring.\n04 OCT 2024  |  VOL 7  |  3\nJournal of Emerging Investigators  \u2022  www.emerginginvestigators.org\nhttps://doi.org/10.59720/24-087 to a constant six. We used LightGBM to model the data, a \npowerful gradient booster that combines accuracy with \nefficiency. Additionally, the hierarchical-based processing \nof the LightGBM model allows for feature importance to be \nestimated (14). The relative importance of each feature was \ncalculated with word count, paragraph count, and pause \nfrequencies being among the most important (Figure 2) . We \nalso graphed and analyzed the types of error (Figure 3) . The \nmodel was fairly even in the errors it made, overestimating \nand underestimating the score an essay received fairly \nequally. Additionally, barring any outliers, the model was at \nmost off by two points for a grade when assessing a given \nessay, indicating that there was generally a strong agreement \nbetween the predictions and the official scores.  To fully understand how the performance of this model \ncompares to LLM based methods and to address our original \nhypothesis, we compared our results to prior research that \nused LLMs to assess the quality of essay writing (16). We \nspecifically examine Table 3 of the paper as it features the \nQWK scores for two tasks most related to our own (automatic \nessay grading with a score range of 1\u20136). Our model scores \nan average QWK of 0.7018 (Figure 4) . In comparison, most of \nthe LLMs featured in the paper achieve under 0.7 for the first \nexperiment and above 0.775 for the second experiment. \nDISCUSSION\n In this paper, we highlight a different way of approaching \nnatural language tasks, one that doesn\u2019t involve the language \nFigure 2: LightGBM\u2019s feature importance. The importance of each feature to the model trained on a specific data split, where a higher \nnumerical value means that a feature is relatively more important than another. This means that a feature. The number of words and paragraphs \nare shown to be most important to the model.\nFigure 1: LightGBM performance on evaluating student essays based on RMSE and QWK. This graph shows the results the model \nobtained for each of the 5 data splits, including its quantitative performance and the time it took to train. An average RMSE of 0.6624 was \nobtained taking 0.3774 seconds on average.\n04 OCT 2024  |  VOL 7  |  4\nJournal of Emerging Investigators  \u2022  www.emerginginvestigators.org\nhttps://doi.org/10.59720/24-087 itself. In the last few years, attention-based methods have \ntaken over the field of NLP. While these methods have \ndrastically improved on the results obtained by older methods, \nthey have also increased the run time and resources required\nto model such data. Right now, the norm appears to be fine-\ntuning models with billions of parameters to achieve strong \nresults on down-stream tasks. Specifically, the transformers \nwe compared to were trained with a Nvidia RTX8000 GPU \nand a majority of the models used had well over a million \nparameters. These results reveal two very important \ncomparisons with our own experiment. Firstly, our own \ngradient booster is able to achieve a very similar performance \non scoring essays as LLMs, as can be seen with the numbers \nabove. Secondly, we can see that without the use of a GPU, \nour own model requires significantly less time or computing \npower due to the significantly smaller nature of the model. \nThis supports our original hypothesis as our gradient booster \nusing keystroke features performs at a level comparable to \ntransformer based LLMs while using less time and computing \npower. \n Keystroke log data also gives us insight that we are not \nable to observe normally with raw textual data. Although \nincorporating keystroke information with the actual text \ndata could further improve results, we found only using the \nkeystroke log data was not only effective but also highly \nefficient. Gradient boosters are extremely quick and precise when handling datasets with a relatively low number of \nfeatures (around 40 used here). Additionally, the writing \nprocess itself offers a new way to view and process textual \ndata. Rather than the words that ended up on the final paper, \nthe words that were deleted, sentences that were edited, and \nother features that are missing from the final product could be \nused as inputs to simpler machine learning models. Machine \nlearning models have been used in the past for processing \ntext, typically paired with embedding models like term \nfrequency-inverse document frequency (TFIDF) vectorizers, \nGLOVE vectors, and FastText amongst many others (17, 18). \nAlthough these methods are often more cost-effective than \ntransformer-based methods, they usually perform worse. \nAdditionally, with almost all of these methods, the textual data \nis transformed into a feature space with a high dimensionality, \nresulting in a time-consuming training time even for smaller \nmachine learning models.\n However, using gradient boosters with keystroke log data, \nwe were able to exploit the writing process to represent an \nessay with a significantly smaller feature set. Additionally, a \nstrong normalized RMSE demonstrates the strong capability \nof gradient boosters trained on keystroke log features. Further \ntask-related optimization could drop this loss further, such as \nmodel fine-tuning or more feature engineering. \n There were some limitations and shortcomings to note \nwhile interpreting these results. The first major limitation \nregards the process of collecting keystroke log data. Unlike \nraw textual data, which can easily be recorded in the form \nof a response or scraped off the internet, keystroke log \ndata requires software to collect the data and permissions \nfrom users. This is a far more complicated process for data \ncollection compared to traditional methods, which could \nmake it difficult to use keystroke log data in certain tasks. \nAdditionally, performing inference with keystroke log data \nwould require keystroke log software to be active while a new \nuser is typing. The data collection phase is more difficult for \nkeystroke log data compared to raw textual data and limits the \nusability of the methods provided here.\n Another limitation faced in this paper is a lack of reliable \ncomparison between keystroke log methods and state of \nthe art transformer-based methods. Due to the anonymous \nFigure 4: Sample time series displaying the number of keystrokes over time. The number of keystrokes in each 60 second time slice \n(sequential segments of 60 second time spans where an index corresponds to the position of the segment) for a single participant while they \nwere writing (blue). It also shows the line of best fit used to determine slope degree (for 30 and 60 second time slices) (orange) and some \nnoticeable local maxes and mins (red).\nFigure 3: Prediction residuals. The above figure shows a histogram \nof the differences between the predictions made and the true targets.\n04 OCT 2024  |  VOL 7  |  5\nJournal of Emerging Investigators  \u2022  www.emerginginvestigators.org\nhttps://doi.org/10.59720/24-087 nature of the data used in this paper, it is not possible to see \nhow a transformer model would have scored on the original \ntext data nor is it possible to see the performance of a hybrid \nmodel. While we did attempt to compare the performance of \nLLMs compared to gradient boosters, this comparison was \nnot made on the same set of data, so it instead serves as a \nrough estimate rather than a completely precise measure.\n Using keystroke log data to model textual inputs is a \nless explored part of NLP and we presented ideas intended \nto serve as a baseline. Several changes or additions could \nimprove the results. These revisions can be as simple as \noptimizing the hyper-parameters of the model and ensembling \nor stacking several models, or as complicated as engineering \nnew features from the time-series component of the data. \nAnother important development could be the creation of \na non-anonymized keystroke log dataset. This would allow \nresearchers the ability to compare the strength of models \nusing keystroke log data to the strength of models using \ntextual data. This could show the validity of keystroke-based \nmethods as well as highlighting the trade-off in efficiency \nversus performance. Additionally, this data could be used to \nexplore hybrid methods which utilize both the final product \nand the process of getting to the final product. Such a model \nwould be able to get a strong variety of features, which could \nallow for even stronger results. Another potentially interesting \nform of research with keystroke log data is a longitudinal \nanalysis. Uncovering changes in the way people type as a \nfunction of time could be both interesting and insightful.\n While we focused on optimizing time complexity, optimizing \nperformance could also be achieved. The easiest and possibly \nmost effective way for achieving stronger results is to adjust \nthe parameters of the model. For example, increasing the \nnumbe",
      "openai_available": true,
      "pages": 7,
      "processed": true,
      "recommendations": [
        "Broaden the research area to make the application more versatile for different NLP tasks",
        "Increase the number of comparable models and techniques to justify the effectiveness of their approach",
        "Collaborate with other researchers or institutions to access better resources",
        "Consider overcoming the limitations such as complicated data collection process, and the requirement of keystroke logging software at the time of new user input",
        "Work on improving the anonymity aspect of the data to make practical comparison of results possible and bring 'real world' validity to the findings."
      ],
      "strengths": [
        "The candidate has published a research paper in a recognized journal",
        "The topic of research provides a new perspective on NLP tasks by focusing on keystroke log information",
        "The research demonstrates clear understanding of the subject matter",
        "Provides comparison between traditional methods and their own approach in terms of efficiency and results",
        "Work has potential for significant impact in expanding the understanding and optimization of NLP models."
      ],
      "summary": "Strengths: \n[SEP] The candidate has published a research paper in a recognized journal \n[SEP] The topic of research provides a new perspective on NLP tasks by focusing on keystroke log information \n[SEP] The research demonstrates clear understanding of the subject matter \n[SEP] Provides comparison between traditional methods and their own approach in terms of efficiency and results \n[SEP] Work has potential for significant impact in expanding the understanding and optimization of NLP models.\n\nWeaknesses: \n[SEP] The research focus is narrow with concentration on keystroke log data, making it less versatile for different NLP tasks \n[SEP] Dependence on expensive and limited resources such as GPUs for training models \n[SEP] Lack of a clear comparison between keystroke log methods and state-of-the-art transformer-based methods \n[SEP] Limitations mentioned in the research, like complications in data collection and inferencing, could be a hurdle.\n\nRecommendations: \n[SEP] Broaden the research area to make the application more versatile for different NLP tasks \n[SEP] Increase the number of comparable models and techniques to justify the effectiveness of their approach \n[SEP] Collaborate with other researchers or institutions to access better resources \n[SEP] Consider overcoming the limitations such as complicated data collection process, and the requirement of keystroke logging software at the time of new user input \n[SEP] Work on improving the anonymity aspect of the data to make practical comparison of results possible and bring 'real world' validity to the findings.",
      "text_preview": "04 OCT 2024  |  VOL 7  |  1\nJournal of Emerging Investigators  \u2022  www.emerginginvestigators.org\nArticleLLM that was built on BERT, is currently ranked seventh for \nthe General Language Understanding Evaluation (GLUE) \nbenchmark (3,4). The GLUE benchmark is a large dataset \nthat creates several fundamental tasks of natural language \nprocessing (NLP) including question answering and text \nclassification, amongst others. The base version of the BERT \nmodel comprises 86 million total parameters while the large \nversion has over 300 million parameters. To be able to fine-tune \nsuch a model on a task, a GPU and a considerable amount of \ntime is required. Additionally, achieving optimal performance \nrequires hyper parameter tweaking, such as training for more/\nless epochs (training iterations) and increasing/decreasing \nthe learning rate (how aggressive the training approach is), \nwhich further the total time complexity. Traditional methods \nattempt to use classical machine learning algorithm",
      "weaknesses": [
        "The research focus is narrow with concentration on keystroke log data, making it less versatile for different NLP tasks",
        "Dependence on expensive and limited resources such as GPUs for training models",
        "Lack of a clear comparison between keystroke log methods and state-of-the-art transformer-based methods",
        "Limitations mentioned in the research, like complications in data collection and inferencing, could be a hurdle."
      ]
    },
    "resume": {
      "extracted_text": "Ryan\nBarretto\nryanbarretto70@gmail.com\n|\n(847)\n246-2461\n|\nChicago,\nIL\nEDUCATION\nWilliam\nFremd\nHigh\nSchool\nMay\n2025\nClass\nof\n2025\n\u25aa\nUnweighted\nGPA\n\u2013\n4.0\n\u25aa\nWeighted\nGPA\n\u2013\n5.37\n\u25aa\nAP\nClasses\n\u2013\n14\nWORK\nEXPERIENCE\nBizzflo\nBusiness\nManagement\nSoftware\nJuly\n2024\nMachine\nLearning\nIntern\nRemote\n\u25aa\nUsed\nArtificial\nIntelligence\nbased\ntools\nto\nautomate\nvideo\ncreation\ndetailing\ninstructional\nbased\nmaterials\nThe\nLearning\nAgency\nLab\nMay\n2023\n\u2013\nAug\n2023\nArtificial\nIntelligence\nIntern\nRemote\n\u25aa\nFocus\non\nNatural\nLanguage\nProcessing\n(NLP),\ncompleting\ntasks\nsuch\nas\nautomatic\nessay\ndetection,\npersonally\nidentifiable\ninformation\n(PII)\ndetection,\nautomatic\ngrammar\ncorrection,\nand\nkeystroke\nlog\nanalysis.\n\u25aa\nUtilized\nstate\nof\nthe\nart\ntechniques\nin\nthe\nfield\nof\nNLP\ninvolving\nattention-based\ntransformer\nmodels\nas\nwell\nas\nmethods\nfrom\nmachine\nlearning\nincluding\ngradient\nboosting.\nKaggle\nJanuary\n2021\n\u2013\nPresent\nPrivate\nContributor\n\u25aa\nPublished\nnumerous\ncode\nnotebooks\nwhich\nearned\nmedals\nincluding\n1\ngold,\n5\nsilver,\nand\n3\nbronze\nand\na\npeak\nglobal\nnotebooks\nranking\nof\n656\nin\nthe\nworld.\n\u25aa\nParticipated\nin\nseveral\ncompetitions\nand\ndiscussion\nthreads\npeaking\nat\n1600th\nin\nthe\nworld\nfor\ncompetitions\nand\n800th\nfor\ndiscussions.\nAWARDS\n\u25aa\nUS\nChess\nCandidate\nMaster\no\n54th\nhighest\nrated\nplayer\nin\nthe\nUS\nfor\nage\n16\no\nUSCF\nrating\n\u2013\n2111\n\u25aa\nSilver\nmedalist\nin\nInvitro\nCell\nResearch\nCompetition\n(101st\nout\nof\n6430).\no\nPredicted\nseveral\nhealth\nrelated\nconditions\ngiven\nanonymized\nmedical\ndata.\nUtilized\ngradient\nboosters\nand\ntabular\nfeature\nextraction\nfor\nthe\nfinal\nsolution.\n\u25aa\nBronze\nmedalist\nin\nGeorgia\nState\nUniversity\nCompetition\n(78th\nout\nof\n1557)\no\nClassified\nargumentative\nelements\nin\nstudent\nwriting\nusing\ntransformer\nmodels,\nlike\nDeBERTa\nand\noptimization\nstrategies\nlike\nAdamW\nfor\nmultivariate\nprediction.\n\u25aa\nUSACO\nSilver\n(United\nStates\nof\nAmerica\nComputing\nOlympiad)\no\nSolved\nalgorithm\nbased\nproblems\ninvolving\ntrees,\ngraphs,\ngreedy\nalgorithms\nand\ndynamic\nprogramming\n\u25aa\nScholastic\nWriting\nSilver\nKey\no\nNon-fiction\nanalytical\nessay\non\nthe\nclose\nrelationship\nbetween\nAI\nand\nchess\nover\nthe\ncourse\nof\nthe\nlast\nfew\ndecades.\n\u25aa\nM3\nMath\nModeling\nHonorable\nMention\no\nCo-wrote\na\npaper\nthat\nused\nmathematical\nmodels\nlike\nARIMA,\nmarkov\nchains,\nlogistic\nregression\nto\nsolve\nhousing\nrelated\nissues\nLEADERSHIP\nEXPERIENCE\n\u25aa\nCofounded\nhigh\nschool\u2019s\nmachine\nlearning\nand\nartificial\nintelligence\nclub\n\u25aa\nChess\nclub\nexec\nboard\n(3\nyears),\nentailing\nhelping\nincoming\nmembers\nimprove\ntheir\ngame\nand\nstrengthening\nthe\nteam.\n\u25aa\nLed\nAI\nworkshop\nfor\ndistrict\nhackathon\nSKILLS\nAND\nINTERESTS\n\u25aa\nSeveral\nyears\nof\nexperience\nwith\nPython,\nand\nspecifically\nframeworks\nsuch\nas\nPytorch,\nTensorflow,\nand\nTransformers\n\u25aa\nExperience\nwith\nC++\nand\nalgorithms\n\u25aa\nSeveral\nyears\nusing\nand\nimplementing\nmachine\nlearning\nmodels\nlike\ngradient\nboosters,\nsupport\nvector\nmachines,\netc\u2026\n\u25aa\nSeveral\nyears\nusing\nand\nimplementing\ndeep\nlearning\nmodels\nlike\ntransformers,\nconvolutional\nneural\nnetworks,\netc\u2026\nPUBLICATIONS\n\u25aa\nGradient\nBoosting\nwith\nTemporal\nFeature\nExtraction\nfor\nModeling\nKeystroke\nLog\nData\n\u2013\nPublished\non\nfigshare\n\u25aa\nHow\nI\nJoined\nA\nKaggle\nCompetition\nAs\nA\nHigh\nSchooler\n\u2013\nPublished\non\nthe\nLearning\nAgency\nLab\nINDEPENDENT\nPROJECTS\n\u25aa\nAI\nBased\nMarket\nForecaster\nand\nTrader\no\nUsed\ntime\nseries\ntransformer\nmodels\nto\nmake\npredictions\non\nthe\nmarket\nand\nthen\nselect\nstocks\nbelieved\nto\nbe\nhighly\nprofitable\n\u25aa\nAutoKeystroke\nLibrary\no\nCreated\na\nlibrary\nreleased\non\npython\nwhich\nallows\nusers\nto\nautomatically\nprocess\nkeystroke\nlog\ndata\nand\nmodel\nthe\ndata",
      "openai_available": true,
      "pages": 2,
      "processed": true,
      "recommendations": [
        "Seek out more professional experience in the field of Machine Learning and Artificial Intelligence, enriching qualifications with practical skills",
        "Add testimonials or references from previous employers, professors or collaborators in your projects",
        "Showcase teamwork or cooperation during previous work experience or projects",
        "If possible, demonstrate openness to relocation or flexibility in your work location",
        "Participate more in collaborative projects, as most high end solutions require effective team working skills."
      ],
      "strengths": [
        "Impressive work experience including internships focused on Machine Learning and Artificial Intelligence",
        "Strong academic performance with a high GPA and completion of numerous AP classes",
        "Proven leadership skills through co-founding a machine learning and AI club in high school and serving on the chess club executive board",
        "Recognition in the form of several awards like the Silver medalist in Invitro Cell Research Competition, Bronze medalist in Georgia State University Competition, etc.",
        "Active engagement on Kaggle, including winning medals",
        "Published works on relevant topics such as gradient boosting and machine learning",
        "Possesses necessary skills such as Python, Tensorflow, Pytorch, C++, etc."
      ],
      "summary": "Strengths: [SEP] Impressive work experience including internships focused on Machine Learning and Artificial Intelligence [SEP] Strong academic performance with a high GPA and completion of numerous AP classes [SEP] Proven leadership skills through co-founding a machine learning and AI club in high school and serving on the chess club executive board [SEP] Recognition in the form of several awards like the Silver medalist in Invitro Cell Research Competition, Bronze medalist in Georgia State University Competition, etc. [SEP] Active engagement on Kaggle, including winning medals [SEP] Published works on relevant topics such as gradient boosting and machine learning [SEP] Possesses necessary skills such as Python, Tensorflow, Pytorch, C++, etc.\n\nWeaknesses: [SEP] Lack of professional experience beyond internships [SEP] No testimonials or references from previous employers or professors [SEP] Limited leadership experience beyond high school [SEP] Limited geographic flexibility, as indicated by current residence in Chicago, IL only [SEP] No mention of any collaborations or teamwork in the projects\n\nRecommendations: [SEP] Seek out more professional experience in the field of Machine Learning and Artificial Intelligence, enriching qualifications with practical skills [SEP] Add testimonials or references from previous employers, professors or collaborators in your projects [SEP] Showcase teamwork or cooperation during previous work experience or projects [SEP] If possible, demonstrate openness to relocation or flexibility in your work location [SEP] Participate more in collaborative projects, as most high end solutions require effective team working skills.",
      "text_preview": "Ryan\nBarretto\nryanbarretto70@gmail.com\n|\n(847)\n246-2461\n|\nChicago,\nIL\nEDUCATION\nWilliam\nFremd\nHigh\nSchool\nMay\n2025\nClass\nof\n2025\n\u25aa\nUnweighted\nGPA\n\u2013\n4.0\n\u25aa\nWeighted\nGPA\n\u2013\n5.37\n\u25aa\nAP\nClasses\n\u2013\n14\nWORK\nEXPERIENCE\nBizzflo\nBusiness\nManagement\nSoftware\nJuly\n2024\nMachine\nLearning\nIntern\nRemote\n\u25aa\nUsed\nArtificial\nIntelligence\nbased\ntools\nto\nautomate\nvideo\ncreation\ndetailing\ninstructional\nbased\nmaterials\nThe\nLearning\nAgency\nLab\nMay\n2023\n\u2013\nAug\n2023\nArtificial\nIntelligence\nIntern\nRemote\n\u25aa\nFocus\non\nNatural\nLanguage\nProcessing\n(NLP),\ncompleting\ntasks\nsuch\nas\nautomatic\nessay\ndetection,\npersonally\nidentifiable\ninformation\n(PII)\ndetection,\nautomatic\ngrammar\ncorrection,\nand\nkeystroke\nlog\nanalysis.\n\u25aa\nUtilized\nstate\nof\nthe\nart\ntechniques\nin\nthe\nfield\nof\nNLP\ninvolving\nattention-based\ntransformer\nmodels\nas\nwell\nas\nmethods\nfrom\nmachine\nlearning\nincluding\ngradient\nboosting.\nKaggle\nJanuary\n2021\n\u2013\nPresent\nPrivate\nContributor\n\u25aa\nPublished\nnumerous\ncode\nnotebooks\nwhich\nearned\nmedals\nincluding\n1\ngold,\n5\nsilver,\nand\n3",
      "weaknesses": [
        "Lack of professional experience beyond internships",
        "No testimonials or references from previous employers or professors",
        "Limited leadership experience beyond high school",
        "Limited geographic flexibility, as indicated by current residence in Chicago, IL only",
        "No mention of any collaborations or teamwork in the projects"
      ]
    }
  },
  "additional_info": {
    "address": "Cannery Row, Monterey, CA 93940, USA",
    "additional_comments": ""
  }
}